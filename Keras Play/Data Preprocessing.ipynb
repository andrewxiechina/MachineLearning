{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "In this section, we will load the data to memory. We will have a collection of different data structures here for future reuse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification Data Load\n",
    "The following code will load data from the directory structure below:\n",
    "\n",
    " \\\\- A\n",
    " \n",
    " \\\\- B\n",
    " \n",
    " \\\\- C\n",
    " \n",
    " Here, (A, B, C) are labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "def load_file(path):\n",
    "    temp = ndimage.imread(path).astype(float)\n",
    "    return temp\n",
    "def load_files(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    result = []\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        try:\n",
    "            temp = load_file(file_path)\n",
    "            result.append(temp)\n",
    "        except:\n",
    "            pass\n",
    "    return np.array(result)\n",
    "def load_classification_data(data_path):\n",
    "    labels = os.listdir(data_path)\n",
    "    arr = []\n",
    "    arr_label = []\n",
    "    for label in labels:\n",
    "        label_path = os.path.join(data_path, label)\n",
    "        print(label_path)\n",
    "        try:\n",
    "            temp = load_files(label_path)\n",
    "        except:\n",
    "            pass\n",
    "        arr.append(temp)\n",
    "        length = len(temp)\n",
    "        str_labels = label * length # Give [\"A\", \"A\", \"A\".....]\n",
    "        arr_label.append(np.array(list(str_labels)))\n",
    "    result_data = np.concatenate((arr), axis=0)\n",
    "    result_label = np.concatenate((arr_label), axis=0)\n",
    "    return result_data, result_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andyxie/workspace/data/notMNIST_small/A\n",
      "/Users/andyxie/workspace/data/notMNIST_small/B\n",
      "/Users/andyxie/workspace/data/notMNIST_small/C\n",
      "/Users/andyxie/workspace/data/notMNIST_small/D\n",
      "/Users/andyxie/workspace/data/notMNIST_small/E\n",
      "/Users/andyxie/workspace/data/notMNIST_small/F\n",
      "/Users/andyxie/workspace/data/notMNIST_small/G\n",
      "/Users/andyxie/workspace/data/notMNIST_small/H\n",
      "/Users/andyxie/workspace/data/notMNIST_small/I\n",
      "/Users/andyxie/workspace/data/notMNIST_small/J\n"
     ]
    }
   ],
   "source": [
    "data, label = load_classification_data(\"/Users/andyxie/workspace/data/notMNIST_small/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "In this section, we will normalize the data. This operation is very crucial, it speeds up the learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, -1.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_depth = 255\n",
    "data_1 = (data - pixel_depth/2)/(pixel_depth/2)\n",
    "data_1.max(), data_1.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "label_1 = pd.get_dummies(label).values\n",
    "label_1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data_2, label_2 = shuffle(data_1, label_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Seperate train, test, validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data_2\n",
    "label_final = label_2\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    data_final, label_final, test_size=0.1)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\n",
    "    \"/Users/andyxie/workspace/input/data_all_flat.npy\", \n",
    "    (X_train, y_train, X_validate, y_validate, X_test, y_test)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
