{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.[1][2] The database is also widely used for training and testing in the field of machine learning.[3][4] It was created by \"re-mixing\" the samples from NIST's original datasets. The creators felt that since NIST's training dataset was taken from American Census Bureau employees, while the testing dataset was taken from American high school students, it was not well-suited for machine learning experiments.[5] Furthermore, the black and white images from NIST were normalized to fit into a 28x28 pixel bounding box and anti-aliased, which introduced grayscale levels.[5]\n",
    "\n",
    "The MNIST database contains 60,000 training images and 10,000 testing images.[6] Half of the training set and half of the test set were taken from NIST's training dataset, while the other half of the training set and the other half of the test set were taken from NIST's testing dataset.[7] There have been a number of scientific papers on attempts to achieve the lowest error rate; one paper, using a hierarchical system of convolutional neural networks, manages to get an error rate on the MNIST database of 0.23 percent.[8] The original creators of the database keep a list of some of the methods tested on it.[5] In their original paper, they use a support vector machine to get an error rate of 0.8 percent.[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Playing with mnist is easy, it comes with keras, the framework we will use for the majority of machine learning tasks. Under it it is tensorflow backend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist # This will load the MNIST dataset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBIAAAFkCAYAAACdGxi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a75655358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_digit(images):\n",
    "    n = len(images)\n",
    "    h = int(n/6) + n%6\n",
    "    plt.figure(figsize=(18,h*3))\n",
    "    for i in range(n):\n",
    "        plt.subplot(h,6,i+1)\n",
    "        plt.imshow(images[i], cmap=plt.get_cmap('gray'))\n",
    "        \n",
    "plot_digit(train_x[:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model with One Hidden Layer\n",
    "The model we will use has only one hidden layer. It looks like this:\n",
    "[...input vector (784, )...] -> [ (784, ) - Relu - (10, ) - Softmax -> [...one hot output (10, )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape input from matrix to vector (784, )\n",
    "n_pixels = train_x.shape[1] * train_x.shape[2] # 28*28 = 784\n",
    "n_train_images = train_x.shape[0]\n",
    "n_test_images = test_x.shape[0]\n",
    "\n",
    "train_x_v = train_x.reshape((n_train_images, n_pixels))\n",
    "test_x_v = test_x.reshape((n_test_images, n_pixels))\n",
    "\n",
    "# Normalize, as the data is between 1-256, we just devide by 256\n",
    "train_x_v = train_x_v/255\n",
    "test_x_v = test_x_v/255\n",
    "\n",
    "train_x_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a multi-classification problem, so transform the y into one-hot\n",
    "from keras.utils import np_utils\n",
    "train_y_o = np_utils.to_categorical(train_y)\n",
    "test_y_o = np_utils.to_categorical(test_y)\n",
    "n_classes = train_y_o.shape[1]\n",
    "train_y_o[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 623,290\n",
      "Trainable params: 623,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This is the model part\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(n_pixels, input_dim=n_pixels, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(n_classes, kernel_initializer='normal', activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10s - loss: 0.2789 - acc: 0.9200 - val_loss: 0.1375 - val_acc: 0.9609\n",
      "Epoch 2/10\n",
      "10s - loss: 0.1104 - acc: 0.9686 - val_loss: 0.0980 - val_acc: 0.9717\n",
      "Epoch 3/10\n",
      "8s - loss: 0.0709 - acc: 0.9795 - val_loss: 0.0737 - val_acc: 0.9755\n",
      "Epoch 4/10\n",
      "8s - loss: 0.0505 - acc: 0.9855 - val_loss: 0.0683 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      "8s - loss: 0.0366 - acc: 0.9896 - val_loss: 0.0644 - val_acc: 0.9793\n",
      "Epoch 6/10\n",
      "9s - loss: 0.0257 - acc: 0.9935 - val_loss: 0.0617 - val_acc: 0.9787\n",
      "Epoch 7/10\n",
      "9s - loss: 0.0204 - acc: 0.9945 - val_loss: 0.0620 - val_acc: 0.9811\n",
      "Epoch 8/10\n",
      "10s - loss: 0.0141 - acc: 0.9968 - val_loss: 0.0618 - val_acc: 0.9810\n",
      "Epoch 9/10\n",
      "8s - loss: 0.0105 - acc: 0.9977 - val_loss: 0.0649 - val_acc: 0.9809\n",
      "Epoch 10/10\n",
      "8s - loss: 0.0080 - acc: 0.9984 - val_loss: 0.0624 - val_acc: 0.9812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aaf8c7da0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x_v, train_y_o, validation_data=(test_x_v, test_y_o), epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform input to (1, 28, 28)\n",
    "n_pixels = train_x.shape[1] * train_x.shape[2] # 28*28 = 784\n",
    "n_train_images = train_x.shape[0]\n",
    "n_test_images = test_x.shape[0]\n",
    "n = train_x.shape[1]\n",
    "train_x_rgb = train_x.reshape(n_train_images, n, n, 1)\n",
    "test_x_rgb = test_x.reshape(n_test_images,n, n, 1)\n",
    "\n",
    "# Normalize\n",
    "train_x_rgb = train_x_rgb/255\n",
    "test_x_rgb = test_x_rgb/255\n",
    "\n",
    "input_shape = train_x_rgb.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape= input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "259s - loss: 0.2229 - acc: 0.9329 - val_loss: 0.0742 - val_acc: 0.9774\n",
      "Epoch 2/12\n",
      "234s - loss: 0.1125 - acc: 0.9665 - val_loss: 0.0526 - val_acc: 0.9838\n",
      "Epoch 3/12\n",
      "237s - loss: 0.0853 - acc: 0.9747 - val_loss: 0.0434 - val_acc: 0.9855\n",
      "Epoch 4/12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-ef9c336ca34b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_x_rgb, train_y_o, validation_data=(test_x_rgb, test_y_o), epochs=12, batch_size=200, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
